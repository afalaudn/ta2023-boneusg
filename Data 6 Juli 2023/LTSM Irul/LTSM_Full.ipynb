{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from scipy import signal, fftpack\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout\n",
    "from keras import utils\n",
    "utils.to_categorical\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = \"E:/Sekolah/Telkom/TA/LTSM/\"\n",
    "save = \"E:/Sekolah/Telkom/TA/LTSM/Img/\"\n",
    "proc_30 = 'E:/Sekolah/Telkom/TA/LTSM/Process/30%/*.csv'\n",
    "proc_50 = 'E:/Sekolah/Telkom/TA/LTSM/Process/50%/*.csv'\n",
    "proc_70 = 'E:/Sekolah/Telkom/TA/LTSM/Process/70%/*.csv'\n",
    "proc_90 = 'E:/Sekolah/Telkom/TA/LTSM/Process/90%/*.csv'\n",
    "combine = 'E:/Sekolah/Telkom/TA/LTSM/Process/Comb/*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 2.0\n",
    "highcut = 10.0\n",
    "fs = 100.0\n",
    "order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_csv =[]\n",
    "for root, dirs, files in os.walk(load):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_load = os.path.join(root, file_name)\n",
    "            files_csv.append(file_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for file_csv in files_csv:\n",
    "   \n",
    "    df = pd.read_csv(file_csv)\n",
    "    var = df['X'].values\n",
    "    data = df['Y'].values\n",
    "     \n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    \n",
    "    #Filter bandpass\n",
    "    filtered_signal = signal.filtfilt(b, a, data)\n",
    "    \n",
    "    # Rectify signal\n",
    "    rectified_signal = np.abs(filtered_signal)\n",
    "    \n",
    "    # One-sided FFT\n",
    "    signal_fft = np.fft.fft(filtered_signal)\n",
    "    signal_freq = np.fft.fftfreq(len(filtered_signal), 1/fs)\n",
    "    n = len(filtered_signal)\n",
    "    freq = signal_freq[0:int(n/2)]\n",
    "    fft_amp = np.abs(signal_fft)[0:int(n/2)]/n*2\n",
    "    \n",
    "    # One-sided PSD\n",
    "    psd = (1/(fs*n)) * np.square(np.abs(signal_fft[:n//2]))\n",
    "    freq_psd = signal_freq[0:int(n/2)]\n",
    "    psd_one_side = psd[0:int(n/2)]\n",
    "    \n",
    "    processed_csv_file = file_csv.replace(\".csv\", \"_processed.csv\")\n",
    "    df.to_csv(processed_csv_file, index=False)\n",
    "    \n",
    "    # fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "\n",
    "    # axs[0, 0].plot(var, filtered_signal)\n",
    "    # axs[0, 0].set_title(file_csv)\n",
    "    # axs[0, 0].set_xlabel('Time (us)')\n",
    "    # axs[0, 0].set_ylabel('Amplitude (V)')\n",
    "\n",
    "    # axs[0, 1].plot(var, rectified_signal)\n",
    "    # axs[0, 1].set_title(file_csv)\n",
    "    # axs[0, 1].set_xlabel('Time (us)')\n",
    "    # axs[0, 1].set_ylabel('Amplitude (V)')\n",
    "\n",
    "    # axs[1, 0].plot(freq, fft_amp)\n",
    "    # axs[1, 0].set_title(file_csv)\n",
    "    # axs[1, 0].set_xlabel('Frequency (MHz)')\n",
    "    # axs[1, 0].set_ylabel('Amplitude Power/Frequency (dB/Hz)')\n",
    "\n",
    "    # axs[1, 1].plot(freq_psd, psd_one_side)\n",
    "    # axs[1, 1].set_title(file_csv)\n",
    "    # axs[1, 1].set_xlabel('Frequency (MHz)')\n",
    "    # axs[1, 1].set_ylabel('Power/Frequency (dB/Hz)')\n",
    "\n",
    "    # save_img = file_csv+\".png\"\n",
    "    # plt.savefig(save_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move PSD to New Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\A301_processed.csv  to  ./Process/A301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\A302_processed.csv  to  ./Process/A302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\A303_processed.csv  to  ./Process/A303_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\A304_processed.csv  to  ./Process/A304_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\A305_processed.csv  to  ./Process/A305_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\K301_processed.csv  to  ./Process/K301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\K302_processed.csv  to  ./Process/K302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\S301_processed.csv  to  ./Process/S301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\S302_processed.csv  to  ./Process/S302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\S303_processed.csv  to  ./Process/S303_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\S304_processed.csv  to  ./Process/S304_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/30%\\S305_processed.csv  to  ./Process/S305_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\A501_processed.csv  to  ./Process/A501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\A502_processed.csv  to  ./Process/A502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\A503_processed.csv  to  ./Process/A503_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\A504_processed.csv  to  ./Process/A504_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\A505_processed.csv  to  ./Process/A505_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\K501_processed.csv  to  ./Process/K501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\K502_processed.csv  to  ./Process/K502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\S501_processed.csv  to  ./Process/S501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\S502_processed.csv  to  ./Process/S502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\S503_processed.csv  to  ./Process/S503_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\S504_processed.csv  to  ./Process/S504_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/50%\\S505_processed.csv  to  ./Process/S505_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\A701_processed.csv  to  ./Process/A701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\A702_processed.csv  to  ./Process/A702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\A703_processed.csv  to  ./Process/A703_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\A704_processed.csv  to  ./Process/A704_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\A705_processed.csv  to  ./Process/A705_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\K701_processed.csv  to  ./Process/K701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\K702_processed.csv  to  ./Process/K702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\S701_processed.csv  to  ./Process/S701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\S702_processed.csv  to  ./Process/S702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\S703_processed.csv  to  ./Process/S703_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\S704_processed.csv  to  ./Process/S704_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/70%\\S705_processed.csv  to  ./Process/S705_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\A901_processed.csv  to  ./Process/A901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\A902_processed.csv  to  ./Process/A902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\A903_processed.csv  to  ./Process/A903_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\A904_processed.csv  to  ./Process/A904_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\A905_processed.csv  to  ./Process/A905_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\K901_processed.csv  to  ./Process/K901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\K902_processed.csv  to  ./Process/K902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\S901_processed.csv  to  ./Process/S901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\S902_processed.csv  to  ./Process/S902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\S903_processed.csv  to  ./Process/S903_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\S904_processed.csv  to  ./Process/S904_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/90%\\S905_processed.csv  to  ./Process/S905_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A301_processed.csv  to  ./Process/A301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A302_processed.csv  to  ./Process/A302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A303_processed.csv  to  ./Process/A303_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A304_processed.csv  to  ./Process/A304_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A305_processed.csv  to  ./Process/A305_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A501_processed.csv  to  ./Process/A501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A502_processed.csv  to  ./Process/A502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A503_processed.csv  to  ./Process/A503_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A504_processed.csv  to  ./Process/A504_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A505_processed.csv  to  ./Process/A505_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A701_processed.csv  to  ./Process/A701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A702_processed.csv  to  ./Process/A702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A703_processed.csv  to  ./Process/A703_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A704_processed.csv  to  ./Process/A704_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A705_processed.csv  to  ./Process/A705_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A901_processed.csv  to  ./Process/A901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A902_processed.csv  to  ./Process/A902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A903_processed.csv  to  ./Process/A903_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A904_processed.csv  to  ./Process/A904_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\A905_processed.csv  to  ./Process/A905_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K301_processed.csv  to  ./Process/K301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K302_processed.csv  to  ./Process/K302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K501_processed.csv  to  ./Process/K501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K502_processed.csv  to  ./Process/K502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K701_processed.csv  to  ./Process/K701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K702_processed.csv  to  ./Process/K702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K901_processed.csv  to  ./Process/K901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\K902_processed.csv  to  ./Process/K902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S301_processed.csv  to  ./Process/S301_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S302_processed.csv  to  ./Process/S302_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S303_processed.csv  to  ./Process/S303_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S304_processed.csv  to  ./Process/S304_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S305_processed.csv  to  ./Process/S305_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S501_processed.csv  to  ./Process/S501_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S502_processed.csv  to  ./Process/S502_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S503_processed.csv  to  ./Process/S503_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S504_processed.csv  to  ./Process/S504_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S505_processed.csv  to  ./Process/S505_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S701_processed.csv  to  ./Process/S701_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S702_processed.csv  to  ./Process/S702_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S703_processed.csv  to  ./Process/S703_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S704_processed.csv  to  ./Process/S704_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S705_processed.csv  to  ./Process/S705_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S901_processed.csv  to  ./Process/S901_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S902_processed.csv  to  ./Process/S902_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S903_processed.csv  to  ./Process/S903_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S904_processed.csv  to  ./Process/S904_processed.csv\n",
      "Moved ' E:/Sekolah/Telkom/TA/LTSM/Process\\S905_processed.csv  to  ./Process/S905_processed.csv\n"
     ]
    }
   ],
   "source": [
    "os.chdir(load)\n",
    "if not os.path.exists(load+\"Process\"):\n",
    "        os.makedirs(load+\"Process\")\n",
    "        print(\"'data' folder created\")\n",
    "        \n",
    "for root, dirs, files in os.walk(load):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"_processed.csv\"):\n",
    "                original_file = os.path.join(root, filename)                \n",
    "                if not \"Process/\" in original_file:\n",
    "                    print(\"Moved '\",original_file,\" to \",\"./Process/\"+filename)\n",
    "                    os.rename(original_file, \"./Process/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabungkan Dataset menjadi satu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan glob untuk mendapatkan daftar file CSV\n",
    "csv_files = glob.glob(proc_30)\n",
    "\n",
    "# Membuat list kosong untuk menyimpan DataFrame dari setiap file CSV\n",
    "dataframes = []\n",
    "\n",
    "# Menggabungkan semua file CSV menjadi satu DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Menggabungkan DataFrame dalam list menjadi satu DataFrame utama\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('E:/Sekolah/Telkom/TA/LTSM/Process/Comb/1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan glob untuk mendapatkan daftar file CSV\n",
    "csv_files = glob.glob(proc_50)\n",
    "\n",
    "# Membuat list kosong untuk menyimpan DataFrame dari setiap file CSV\n",
    "dataframes = []\n",
    "\n",
    "# Menggabungkan semua file CSV menjadi satu DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Menggabungkan DataFrame dalam list menjadi satu DataFrame utama\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('E:/Sekolah/Telkom/TA/LTSM/Process/Comb/2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan glob untuk mendapatkan daftar file CSV\n",
    "csv_files = glob.glob(proc_70)\n",
    "\n",
    "# Membuat list kosong untuk menyimpan DataFrame dari setiap file CSV\n",
    "dataframes = []\n",
    "\n",
    "# Menggabungkan semua file CSV menjadi satu DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Menggabungkan DataFrame dalam list menjadi satu DataFrame utama\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('E:/Sekolah/Telkom/TA/LTSM/Process/Comb/3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan glob untuk mendapatkan daftar file CSV\n",
    "csv_files = glob.glob(proc_90)\n",
    "\n",
    "# Membuat list kosong untuk menyimpan DataFrame dari setiap file CSV\n",
    "dataframes = []\n",
    "\n",
    "# Menggabungkan semua file CSV menjadi satu DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Menggabungkan DataFrame dalam list menjadi satu DataFrame utama\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('E:/Sekolah/Telkom/TA/LTSM/Process/Comb/4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 X         Y    label\n",
      "0         5.000000 -0.035156  label_1\n",
      "1         5.015625 -0.035156  label_1\n",
      "2         5.031250 -0.039062  label_1\n",
      "3         5.046875 -0.007812  label_1\n",
      "4         5.062500  0.117188  label_1\n",
      "...            ...       ...      ...\n",
      "599035  199.921875 -0.003906  label_4\n",
      "599036  199.937500 -0.003906  label_4\n",
      "599037  199.953125  0.000000  label_4\n",
      "599038  199.968750 -1.523438  label_4\n",
      "599039  199.984375  1.519531  label_4\n",
      "\n",
      "[599040 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "merge = 'E:/Sekolah/Telkom/TA/LTSM/Process/Comb/All.csv'\n",
    "\n",
    "# Menggunakan glob untuk mendapatkan daftar file CSV\n",
    "csv_files = glob.glob(combine)\n",
    "\n",
    "# Membuat list kosong untuk menyimpan DataFrame dari setiap file CSV\n",
    "dataframes = []\n",
    "\n",
    "# Menggabungkan semua file CSV menjadi satu DataFrame\n",
    "for i, file in enumerate(csv_files):\n",
    "    df = pd.read_csv(file)\n",
    "    df['label'] = f'label_{i+1}'\n",
    "    dataframes.append(df)\n",
    "# Menggabungkan DataFrame dalam list menjadi satu DataFrame utama\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Menampilkan hasil gabungan\n",
    "print(combined_df)\n",
    "\n",
    "combined_df.to_csv(merge, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(merge)\n",
    "\n",
    "label_mapping = {\n",
    "    'label_1': 'Density 30%',\n",
    "    'label_2': 'Density 50%',\n",
    "    'label_3': 'Density 70%',\n",
    "    'label_4': 'Density 90%'\n",
    "}\n",
    "\n",
    "data_df['label'] = data_df['label'].map(label_mapping)\n",
    "data_df.to_csv(merge, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset utama untuk pelatihan\n",
    "data_df = pd.read_csv(merge)\n",
    "X = data_df.iloc[:, :-1].values\n",
    "y = data_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599040, 4)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan LabelEncoder untuk mengubah label menjadi nilai numerik\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_encoded_categorical = utils.to_categorical(y_encoded)\n",
    "print(y_encoded_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi dataset menjadi data pelatihan dan data validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded_categorical, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(y_encoded_categorical.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model dengan dataset utama\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('All.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('All.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Datates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset yang ingin diprediksi\n",
    "predict_df = pd.read_csv('E:/Sekolah/Telkom/TA/LTSM/Process/50%/K502_processed.csv')\n",
    "X_predict = predict_df.iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Memprediksi label menggunakan model yang telah dilatih\n",
    "y_pred_encoded = model.predict(X_predict)\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "y_pred_label = label_encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = predict_df.copy()\n",
    "result_df['predicted_label'] = y_pred_label\n",
    "result_df.to_csv('data_predict_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label\n",
      "Density 50%    8802\n",
      "Density 90%    2710\n",
      "Density 30%     591\n",
      "Density 70%     377\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_df['predicted_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data match : Density 50%\n"
     ]
    }
   ],
   "source": [
    "# Membandingkan kemiripan label dengan dataset utama\n",
    "similar_labels = []\n",
    "for label in result_df['predicted_label'].unique():\n",
    "    similarity = max(SequenceMatcher(None, label, unique_label).ratio() for unique_label in np.unique(y))\n",
    "if similarity > 0.7:\n",
    "    print(\"Data match :\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Piye carane ben iso muncul 1 dataset tok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
